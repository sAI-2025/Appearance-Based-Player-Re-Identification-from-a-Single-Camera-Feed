{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJXEq2KAfcX8"
      },
      "source": [
        "# Re-identification in a Single Feed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from collections import defaultdict, deque\n",
        "import time\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cdist\n",
        "import pickle\n",
        "import os\n",
        "from IPython.display import HTML, display\n",
        "import base64\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-qlh2eEms7Dt",
        "outputId": "d22bdd59-9326-4a1f-8b40-7665520bca18"
      },
      "outputs": [],
      "source": [
        "class PlayerReIDTracker:\n",
        "    \"\"\"\n",
        "    Real-time Player Re-Identification and Tracking System for Football\n",
        "\n",
        "    This system uses YOLOv11 for detection and implements custom Re-ID logic\n",
        "    to maintain consistent player identities across occlusions and re-entries.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_path, video_path, conf_threshold=0.3, iou_threshold=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the tracking system\n",
        "\n",
        "        Args:\n",
        "            model_path (str): Path to YOLOv11 model\n",
        "            video_path (str): Path to input video\n",
        "            conf_threshold (float): Confidence threshold for detections\n",
        "            iou_threshold (float): IoU threshold for NMS\n",
        "        \"\"\"\n",
        "        self.model = YOLO(model_path)\n",
        "        self.video_path = video_path\n",
        "        self.conf_threshold = conf_threshold\n",
        "        self.iou_threshold = iou_threshold\n",
        "\n",
        "        # Tracking parameters\n",
        "        self.max_disappeared = 30  # Frames before considering a player gone\n",
        "        self.max_distance = 150    # Maximum distance for ID assignment\n",
        "        self.appearance_threshold = 0.6  # Cosine similarity threshold for Re-ID\n",
        "\n",
        "        # Class mapping - ONLY goalkeeper and player\n",
        "        self.class_names = {0: 'ball', 1: 'goalkeeper', 2: 'player', 3: 'referee'}\n",
        "        self.target_classes = [1, 2]  # Focus ONLY on goalkeepers and players\n",
        "\n",
        "        # Color filtering parameters for yellowish/green colors\n",
        "        self.excluded_colors = [\n",
        "            (127, 255, 0),   # #7fff00\n",
        "            (153, 255, 51),  # #99ff33\n",
        "            (178, 255, 102), # #b2ff66\n",
        "            (204, 255, 153)  # #ccff99\n",
        "        ]\n",
        "        self.color_threshold = 0.3  # 30% threshold for color matching\n",
        "\n",
        "        # Tracking state\n",
        "        self.next_id = 0\n",
        "        self.active_tracks = {}  # Currently active tracks\n",
        "        self.disappeared_tracks = {}  # Recently disappeared tracks\n",
        "        self.track_history = defaultdict(lambda: deque(maxlen=50))  # Track position history\n",
        "        self.appearance_features = {}  # Store appearance features for Re-ID\n",
        "\n",
        "        # Performance metrics\n",
        "        self.frame_count = 0\n",
        "        self.processing_times = []\n",
        "\n",
        "        # Colab compatibility\n",
        "        self.is_colab = self._check_colab_environment()\n",
        "\n",
        "    def _check_colab_environment(self):\n",
        "        \"\"\"Check if running in Google Colab\"\"\"\n",
        "        try:\n",
        "            import google.colab\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "\n",
        "    def _has_excluded_color(self, frame, bbox):\n",
        "        \"\"\"\n",
        "        Check if the bounding box region contains more than 30% of excluded colors\n",
        "\n",
        "        Args:\n",
        "            frame (np.array): Input frame\n",
        "            bbox (tuple): Bounding box coordinates (x1, y1, x2, y2)\n",
        "\n",
        "        Returns:\n",
        "            bool: True if object should be excluded due to color\n",
        "        \"\"\"\n",
        "        x1, y1, x2, y2 = map(int, bbox)\n",
        "\n",
        "        # Ensure coordinates are within frame bounds\n",
        "        h, w = frame.shape[:2]\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(w, x2), min(h, y2)\n",
        "\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            return False\n",
        "\n",
        "        # Extract ROI\n",
        "        roi = frame[y1:y2, x1:x2]\n",
        "\n",
        "        if roi.size == 0:\n",
        "            return False\n",
        "\n",
        "        # Convert BGR to RGB for color comparison\n",
        "        roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
        "        total_pixels = roi_rgb.shape[0] * roi_rgb.shape[1]\n",
        "\n",
        "        excluded_pixel_count = 0\n",
        "\n",
        "        # Check each excluded color\n",
        "        for target_color in self.excluded_colors:\n",
        "            # Create color range (allowing some tolerance)\n",
        "            tolerance = 30\n",
        "            lower_bound = np.array([max(0, c - tolerance) for c in target_color])\n",
        "            upper_bound = np.array([min(255, c + tolerance) for c in target_color])\n",
        "\n",
        "            # Create mask for this color range\n",
        "            mask = cv2.inRange(roi_rgb, lower_bound, upper_bound)\n",
        "            excluded_pixel_count += np.sum(mask > 0)\n",
        "\n",
        "        # Calculate percentage of excluded color pixels\n",
        "        excluded_percentage = excluded_pixel_count / total_pixels\n",
        "\n",
        "        # Return True if more than 30% of pixels match excluded colors\n",
        "        return excluded_percentage > self.color_threshold\n",
        "\n",
        "    def extract_appearance_features(self, frame, bbox):\n",
        "        \"\"\"\n",
        "        Extract appearance features from a bounding box region\n",
        "\n",
        "        Args:\n",
        "            frame (np.array): Input frame\n",
        "            bbox (tuple): Bounding box coordinates (x1, y1, x2, y2)\n",
        "\n",
        "        Returns:\n",
        "            np.array: Normalized appearance feature vector\n",
        "        \"\"\"\n",
        "        x1, y1, x2, y2 = map(int, bbox)\n",
        "\n",
        "        # Ensure coordinates are within frame bounds\n",
        "        h, w = frame.shape[:2]\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(w, x2), min(h, y2)\n",
        "\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            return np.zeros(128)  # Return zero vector for invalid bbox\n",
        "\n",
        "        # Extract ROI\n",
        "        roi = frame[y1:y2, x1:x2]\n",
        "\n",
        "        if roi.size == 0:\n",
        "            return np.zeros(128)\n",
        "\n",
        "        # Resize to standard size\n",
        "        try:\n",
        "            roi_resized = cv2.resize(roi, (64, 128))\n",
        "        except:\n",
        "            return np.zeros(128)\n",
        "\n",
        "        # Extract color histogram features\n",
        "        hist_features = []\n",
        "        for i in range(3):  # BGR channels\n",
        "            hist = cv2.calcHist([roi_resized], [i], None, [32], [0, 256])\n",
        "            hist_features.extend(hist.flatten())\n",
        "\n",
        "        # Extract texture features using LBP-like approach\n",
        "        gray_roi = cv2.cvtColor(roi_resized, cv2.COLOR_BGR2GRAY)\n",
        "        texture_features = self._extract_texture_features(gray_roi)\n",
        "\n",
        "        # Combine features\n",
        "        features = np.concatenate([hist_features, texture_features])\n",
        "\n",
        "        # Normalize features\n",
        "        norm = np.linalg.norm(features)\n",
        "        if norm > 0:\n",
        "            features = features / norm\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_texture_features(self, gray_image):\n",
        "        \"\"\"Extract simple texture features\"\"\"\n",
        "        if gray_image.size == 0:\n",
        "            return np.zeros(6)\n",
        "\n",
        "        # Compute gradients\n",
        "        grad_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        grad_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "        # Compute statistics\n",
        "        features = [\n",
        "            np.mean(grad_x), np.std(grad_x),\n",
        "            np.mean(grad_y), np.std(grad_y),\n",
        "            np.mean(gray_image), np.std(gray_image)\n",
        "        ]\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "    def calculate_distance(self, box1, box2):\n",
        "        \"\"\"Calculate Euclidean distance between box centers\"\"\"\n",
        "        center1 = [(box1[0] + box1[2]) / 2, (box1[1] + box1[3]) / 2]\n",
        "        center2 = [(box2[0] + box2[2]) / 2, (box2[1] + box2[3]) / 2]\n",
        "\n",
        "        return np.sqrt(sum((a - b) ** 2 for a, b in zip(center1, center2)))\n",
        "\n",
        "    def calculate_iou(self, box1, box2):\n",
        "        \"\"\"Calculate IoU between two bounding boxes\"\"\"\n",
        "        x1, y1, x2, y2 = box1\n",
        "        x1_p, y1_p, x2_p, y2_p = box2\n",
        "\n",
        "        # Calculate intersection\n",
        "        xi1 = max(x1, x1_p)\n",
        "        yi1 = max(y1, y1_p)\n",
        "        xi2 = min(x2, x2_p)\n",
        "        yi2 = min(y2, y2_p)\n",
        "\n",
        "        if xi2 <= xi1 or yi2 <= yi1:\n",
        "            return 0\n",
        "\n",
        "        intersection = (xi2 - xi1) * (yi2 - yi1)\n",
        "\n",
        "        # Calculate union\n",
        "        area1 = (x2 - x1) * (y2 - y1)\n",
        "        area2 = (x2_p - x1_p) * (y2_p - y1_p)\n",
        "        union = area1 + area2 - intersection\n",
        "\n",
        "        return intersection / union if union > 0 else 0\n",
        "\n",
        "    def update_tracks(self, frame, detections):\n",
        "        \"\"\"\n",
        "        Update tracking state with new detections\n",
        "\n",
        "        Args:\n",
        "            frame (np.array): Current frame\n",
        "            detections (list): List of detection results\n",
        "\n",
        "        Returns:\n",
        "            dict: Updated tracking results\n",
        "        \"\"\"\n",
        "        current_detections = []\n",
        "\n",
        "        # Process detections with filtering\n",
        "        for detection in detections:\n",
        "            bbox = detection[:4]  # x1, y1, x2, y2\n",
        "            conf = detection[4]\n",
        "            class_id = int(detection[5])\n",
        "\n",
        "            # ONLY process goalkeeper and player classes\n",
        "            if class_id in self.target_classes and conf > self.conf_threshold:\n",
        "                # Check if object has excluded colors\n",
        "                if self._has_excluded_color(frame, bbox):\n",
        "                    print(f\"Excluding object due to yellowish/green color content > 30%\")\n",
        "                    continue\n",
        "\n",
        "                # Extract appearance features\n",
        "                features = self.extract_appearance_features(frame, bbox)\n",
        "\n",
        "                current_detections.append({\n",
        "                    'bbox': bbox,\n",
        "                    'conf': conf,\n",
        "                    'class_id': class_id,\n",
        "                    'features': features\n",
        "                })\n",
        "\n",
        "        # Assignment phase\n",
        "        assigned_tracks = {}\n",
        "        unassigned_detections = list(range(len(current_detections)))\n",
        "\n",
        "        if self.active_tracks:\n",
        "            # Calculate cost matrix\n",
        "            cost_matrix = self._calculate_cost_matrix(current_detections)\n",
        "\n",
        "            # Perform assignment using greedy approach\n",
        "            assignments = self._greedy_assignment(cost_matrix)\n",
        "\n",
        "            # Update assigned tracks\n",
        "            for track_id, det_idx in assignments:\n",
        "                if det_idx < len(current_detections):\n",
        "                    detection = current_detections[det_idx]\n",
        "\n",
        "                    # Update track with new detection\n",
        "                    if track_id in self.active_tracks:\n",
        "                        self.active_tracks[track_id].update({\n",
        "                            'bbox': detection['bbox'],\n",
        "                            'conf': detection['conf'],\n",
        "                            'class_id': detection['class_id'],\n",
        "                            'features': detection['features'],\n",
        "                            'age': self.active_tracks[track_id].get('age', 0) + 1,\n",
        "                            'disappeared': 0\n",
        "                        })\n",
        "                        assigned_tracks[track_id] = self.active_tracks[track_id]\n",
        "\n",
        "                        # Update track history (for center point only, not for drawing lines)\n",
        "                        center = [(detection['bbox'][0] + detection['bbox'][2]) / 2,\n",
        "                                (detection['bbox'][1] + detection['bbox'][3]) / 2]\n",
        "                        self.track_history[track_id].append(center)\n",
        "\n",
        "                    if det_idx in unassigned_detections:\n",
        "                        unassigned_detections.remove(det_idx)\n",
        "\n",
        "        # Handle unassigned detections\n",
        "        for det_idx in unassigned_detections:\n",
        "            detection = current_detections[det_idx]\n",
        "\n",
        "            # Check if this detection matches any disappeared track (Re-ID)\n",
        "            best_match_id = self._find_reid_match(detection['features'])\n",
        "\n",
        "            if best_match_id is not None:\n",
        "                # Reactivate disappeared track\n",
        "                disappeared_track = self.disappeared_tracks[best_match_id]\n",
        "                disappeared_track.update({\n",
        "                    'bbox': detection['bbox'],\n",
        "                    'conf': detection['conf'],\n",
        "                    'class_id': detection['class_id'],\n",
        "                    'features': detection['features'],\n",
        "                    'disappeared': 0\n",
        "                })\n",
        "                self.active_tracks[best_match_id] = disappeared_track\n",
        "                assigned_tracks[best_match_id] = disappeared_track\n",
        "\n",
        "                # Remove from disappeared tracks\n",
        "                if best_match_id in self.disappeared_tracks:\n",
        "                    del self.disappeared_tracks[best_match_id]\n",
        "\n",
        "                print(f\"Re-ID successful: Track {best_match_id} reactivated\")\n",
        "            else:\n",
        "                # Create new track\n",
        "                new_track = {\n",
        "                    'id': self.next_id,\n",
        "                    'bbox': detection['bbox'],\n",
        "                    'conf': detection['conf'],\n",
        "                    'class_id': detection['class_id'],\n",
        "                    'features': detection['features'],\n",
        "                    'age': 1,\n",
        "                    'disappeared': 0\n",
        "                }\n",
        "                self.active_tracks[self.next_id] = new_track\n",
        "                assigned_tracks[self.next_id] = new_track\n",
        "                self.appearance_features[self.next_id] = detection['features']\n",
        "\n",
        "                # Initialize track history\n",
        "                center = [(detection['bbox'][0] + detection['bbox'][2]) / 2,\n",
        "                        (detection['bbox'][1] + detection['bbox'][3]) / 2]\n",
        "                self.track_history[self.next_id].append(center)\n",
        "\n",
        "                print(f\"New track created: ID {self.next_id}\")\n",
        "                self.next_id += 1\n",
        "\n",
        "        # Handle disappeared tracks\n",
        "        disappeared_ids = []\n",
        "        for track_id, track in self.active_tracks.items():\n",
        "            if track_id not in assigned_tracks:\n",
        "                track['disappeared'] += 1\n",
        "                if track['disappeared'] > self.max_disappeared:\n",
        "                    disappeared_ids.append(track_id)\n",
        "                    print(f\"Track {track_id} permanently lost\")\n",
        "                else:\n",
        "                    self.disappeared_tracks[track_id] = track\n",
        "\n",
        "        # Remove completely disappeared tracks\n",
        "        for track_id in disappeared_ids:\n",
        "            if track_id in self.active_tracks:\n",
        "                del self.active_tracks[track_id]\n",
        "            if track_id in self.disappeared_tracks:\n",
        "                del self.disappeared_tracks[track_id]\n",
        "            if track_id in self.appearance_features:\n",
        "                del self.appearance_features[track_id]\n",
        "            if track_id in self.track_history:\n",
        "                del self.track_history[track_id]\n",
        "\n",
        "        # Update active tracks\n",
        "        self.active_tracks = assigned_tracks\n",
        "\n",
        "        return assigned_tracks\n",
        "\n",
        "    def _calculate_cost_matrix(self, detections):\n",
        "        \"\"\"Calculate cost matrix for assignment\"\"\"\n",
        "        track_ids = list(self.active_tracks.keys())\n",
        "        cost_matrix = np.full((len(track_ids), len(detections)), float('inf'))\n",
        "\n",
        "        for i, track_id in enumerate(track_ids):\n",
        "            track = self.active_tracks[track_id]\n",
        "            track_bbox = track['bbox']\n",
        "\n",
        "            for j, detection in enumerate(detections):\n",
        "                det_bbox = detection['bbox']\n",
        "\n",
        "                # Calculate spatial distance\n",
        "                spatial_distance = self.calculate_distance(track_bbox, det_bbox)\n",
        "\n",
        "                # Calculate appearance similarity\n",
        "                try:\n",
        "                    appearance_sim = cosine_similarity(\n",
        "                        [track['features']], [detection['features']]\n",
        "                    )[0][0]\n",
        "                except:\n",
        "                    appearance_sim = 0\n",
        "\n",
        "                # Calculate IoU\n",
        "                iou = self.calculate_iou(track_bbox, det_bbox)\n",
        "\n",
        "                # Combined cost (lower is better)\n",
        "                if spatial_distance < self.max_distance:\n",
        "                    # Weighted combination of distance, appearance, and IoU\n",
        "                    cost = (spatial_distance * 0.5) - (appearance_sim * 50) - (iou * 30)\n",
        "                    cost_matrix[i, j] = cost\n",
        "\n",
        "        return cost_matrix\n",
        "\n",
        "    def _greedy_assignment(self, cost_matrix):\n",
        "        \"\"\"Simplified greedy assignment\"\"\"\n",
        "        assignments = []\n",
        "        track_ids = list(self.active_tracks.keys())\n",
        "\n",
        "        used_tracks = set()\n",
        "        used_detections = set()\n",
        "\n",
        "        # Sort by cost\n",
        "        costs = []\n",
        "        for i in range(cost_matrix.shape[0]):\n",
        "            for j in range(cost_matrix.shape[1]):\n",
        "                if cost_matrix[i, j] != float('inf'):\n",
        "                    costs.append((cost_matrix[i, j], track_ids[i], j))\n",
        "\n",
        "        costs.sort()\n",
        "\n",
        "        for cost, track_id, det_idx in costs:\n",
        "            if track_id not in used_tracks and det_idx not in used_detections:\n",
        "                assignments.append((track_id, det_idx))\n",
        "                used_tracks.add(track_id)\n",
        "                used_detections.add(det_idx)\n",
        "\n",
        "        return assignments\n",
        "\n",
        "    def _find_reid_match(self, features):\n",
        "        \"\"\"Find best Re-ID match from disappeared tracks\"\"\"\n",
        "        best_match_id = None\n",
        "        best_similarity = 0\n",
        "\n",
        "        for track_id, track in self.disappeared_tracks.items():\n",
        "            try:\n",
        "                similarity = cosine_similarity([features], [track['features']])[0][0]\n",
        "\n",
        "                if similarity > self.appearance_threshold and similarity > best_similarity:\n",
        "                    best_similarity = similarity\n",
        "                    best_match_id = track_id\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        return best_match_id\n",
        "\n",
        "    def process_video(self, output_path=None, display_interval=30, save_frames=False):\n",
        "        \"\"\"\n",
        "        Process the entire video with tracking and Re-ID\n",
        "\n",
        "        Args:\n",
        "            output_path (str): Path to save output video\n",
        "            display_interval (int): Show frame every N frames in Colab\n",
        "            save_frames (bool): Save individual frames\n",
        "        \"\"\"\n",
        "        cap = cv2.VideoCapture(self.video_path)\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"Cannot open video file: {self.video_path}\")\n",
        "\n",
        "        # Get video properties\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        # Initialize video writer if output path provided\n",
        "        writer = None\n",
        "        if output_path:\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        print(f\"Processing video: {width}x{height} at {fps} FPS\")\n",
        "        print(f\"Total frames: {total_frames}\")\n",
        "        print(f\"Tracking only: Goalkeepers and Players\")\n",
        "        print(f\"Excluding yellowish/green colored objects with >30% color content\")\n",
        "\n",
        "        frame_times = []\n",
        "        frames_to_display = []\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Run detection\n",
        "            results = self.model(frame, conf=self.conf_threshold, iou=self.iou_threshold, verbose=False)\n",
        "\n",
        "            # Convert results to numpy array\n",
        "            detections = []\n",
        "            if results[0].boxes is not None:\n",
        "                boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "                confs = results[0].boxes.conf.cpu().numpy()\n",
        "                classes = results[0].boxes.cls.cpu().numpy()\n",
        "\n",
        "                for i in range(len(boxes)):\n",
        "                    detections.append([\n",
        "                        boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3],\n",
        "                        confs[i], classes[i]\n",
        "                    ])\n",
        "\n",
        "            # Update tracking\n",
        "            tracks = self.update_tracks(frame, detections)\n",
        "\n",
        "            # Draw tracking results (without trajectory lines)\n",
        "            annotated_frame = self.draw_tracks(frame, tracks)\n",
        "\n",
        "            # Calculate processing time\n",
        "            processing_time = time.time() - start_time\n",
        "            frame_times.append(processing_time)\n",
        "\n",
        "            # Add performance info\n",
        "            cv2.putText(annotated_frame, f\"Frame: {self.frame_count}/{total_frames}\",\n",
        "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "            cv2.putText(annotated_frame, f\"FPS: {1/processing_time:.1f}\",\n",
        "                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "            cv2.putText(annotated_frame, f\"Active: {len(tracks)}\",\n",
        "                       (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "            cv2.putText(annotated_frame, f\"Disappeared: {len(self.disappeared_tracks)}\",\n",
        "                       (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "            # Save frame if writer available\n",
        "            if writer:\n",
        "                writer.write(annotated_frame)\n",
        "\n",
        "            # Save frames for display in Colab\n",
        "            if self.is_colab and (self.frame_count % display_interval == 0 or self.frame_count < 5):\n",
        "                frames_to_display.append((self.frame_count, annotated_frame.copy()))\n",
        "\n",
        "            # Save individual frames if requested\n",
        "            if save_frames and self.frame_count % 30 == 0:\n",
        "                frame_path = f\"frame_{self.frame_count:04d}.jpg\"\n",
        "                cv2.imwrite(frame_path, annotated_frame)\n",
        "\n",
        "            self.frame_count += 1\n",
        "\n",
        "            # Print progress\n",
        "            if self.frame_count % 30 == 0:\n",
        "                avg_fps = 1 / np.mean(frame_times[-30:])\n",
        "                progress = (self.frame_count / total_frames) * 100\n",
        "                print(f\"Progress: {progress:.1f}% - Frame {self.frame_count}/{total_frames} - Avg FPS: {avg_fps:.1f}\")\n",
        "\n",
        "        # Cleanup\n",
        "        cap.release()\n",
        "        if writer:\n",
        "            writer.release()\n",
        "\n",
        "        # Display frames in Colab\n",
        "        if self.is_colab and frames_to_display:\n",
        "            self._display_frames_in_colab(frames_to_display)\n",
        "\n",
        "        # Print final statistics\n",
        "        if frame_times:\n",
        "            avg_processing_time = np.mean(frame_times)\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"PROCESSING COMPLETE!\")\n",
        "            print(f\"{'='*50}\")\n",
        "            print(f\"Total frames processed: {self.frame_count}\")\n",
        "            print(f\"Average processing time: {avg_processing_time:.4f}s\")\n",
        "            print(f\"Average FPS: {1/avg_processing_time:.1f}\")\n",
        "            print(f\"Total unique players detected: {self.next_id}\")\n",
        "            print(f\"Final active tracks: {len(self.active_tracks)}\")\n",
        "            print(f\"Final disappeared tracks: {len(self.disappeared_tracks)}\")\n",
        "\n",
        "            if output_path:\n",
        "                print(f\"Output video saved to: {output_path}\")\n",
        "\n",
        "        return self.frame_count, self.next_id\n",
        "\n",
        "    def _display_frames_in_colab(self, frames_to_display):\n",
        "        \"\"\"Display frames in Google Colab\"\"\"\n",
        "        print(f\"\\nDisplaying {len(frames_to_display)} sample frames:\")\n",
        "\n",
        "        for frame_num, frame in frames_to_display:\n",
        "            print(f\"\\n--- Frame {frame_num} ---\")\n",
        "            # Convert BGR to RGB for display\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.imshow(frame_rgb)\n",
        "            plt.title(f\"Frame {frame_num} - Football Player Tracking (No Lines, Players/GK Only)\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "    def draw_tracks(self, frame, tracks):\n",
        "        \"\"\"Draw tracking results on frame WITHOUT trajectory lines\"\"\"\n",
        "        annotated_frame = frame.copy()\n",
        "\n",
        "        # Define colors for different classes\n",
        "        colors = {\n",
        "            1: (0, 255, 0),    # Goalkeeper - Green\n",
        "            2: (255, 0, 0),    # Player - Blue\n",
        "        }\n",
        "\n",
        "        # Generate unique colors for each track ID\n",
        "        track_colors = {}\n",
        "        for track_id in tracks.keys():\n",
        "            if track_id not in track_colors:\n",
        "                # Generate a unique color based on track ID\n",
        "                np.random.seed(track_id)\n",
        "                color = tuple(np.random.randint(0, 255, 3).tolist())\n",
        "                track_colors[track_id] = color\n",
        "\n",
        "        for track_id, track in tracks.items():\n",
        "            bbox = track['bbox']\n",
        "            class_id = track['class_id']\n",
        "            conf = track['conf']\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "\n",
        "            # Use class color or unique track color\n",
        "            color = colors.get(class_id, track_colors.get(track_id, (255, 255, 255)))\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "            # Draw track ID and class\n",
        "            label = f\"ID:{track_id} {self.class_names[class_id]} {conf:.2f}\"\n",
        "            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
        "\n",
        "            # Draw label background\n",
        "            cv2.rectangle(annotated_frame, (x1, y1 - label_size[1] - 10),\n",
        "                         (x1 + label_size[0], y1), color, -1)\n",
        "\n",
        "            # Draw label text\n",
        "            cv2.putText(annotated_frame, label, (x1, y1 - 5),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "            # Draw center point\n",
        "            center_x = (x1 + x2) // 2\n",
        "            center_y = (y1 + y2) // 2\n",
        "            cv2.circle(annotated_frame, (center_x, center_y), 4, color, -1)\n",
        "\n",
        "            # REMOVED: Trajectory line drawing\n",
        "            # The track history is still maintained for Re-ID purposes but not drawn\n",
        "\n",
        "        return annotated_frame\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the tracking system\"\"\"\n",
        "    # Configuration\n",
        "    MODEL_PATH = \"/content/drive/MyDrive/Colab Notebooks/Assignment/P2_best.pt\"\n",
        "    VIDEO_PATH = \"/content/drive/MyDrive/Colab Notebooks/Assignment/15sec_input_720p.mp4\"\n",
        "    OUTPUT_PATH = \"/content/drive/MyDrive/Colab Notebooks/Assignment/output/tracked_output.mp4\"\n",
        "\n",
        "    # Tracking parameters\n",
        "    CONF_THRESHOLD = 0.25  # Lowered for better detection\n",
        "    IOU_THRESHOLD = 0.5\n",
        "\n",
        "    print(\"ðŸˆ Initializing Football Player Re-ID Tracking System...\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"âœ… Modifications Applied:\")\n",
        "    print(\"   - Trajectory lines removed\")\n",
        "    print(\"   - Only tracking Goalkeepers and Players\")\n",
        "    print(\"   - Yellowish/green color filtering enabled\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
        "\n",
        "    # Initialize tracker\n",
        "    tracker = PlayerReIDTracker(\n",
        "        model_path=MODEL_PATH,\n",
        "        video_path=VIDEO_PATH,\n",
        "        conf_threshold=CONF_THRESHOLD,\n",
        "        iou_threshold=IOU_THRESHOLD\n",
        "    )\n",
        "\n",
        "    # Process video\n",
        "    try:\n",
        "        total_frames, total_players = tracker.process_video(\n",
        "            output_path=OUTPUT_PATH,\n",
        "            display_interval=25,  # Show every 25th frame in Colab\n",
        "            save_frames=False\n",
        "        )\n",
        "\n",
        "        print(f\"\\nâœ… SUCCESS!\")\n",
        "        print(f\"ðŸ“Š Processed {total_frames} frames\")\n",
        "        print(f\"ðŸ‘¥ Detected {total_players} unique players\")\n",
        "        print(f\"ðŸ’¾ Output saved to: {OUTPUT_PATH}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error processing video: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    success = main()\n",
        "    if success:\n",
        "        print(\"\\nðŸŽ‰ Tracking completed successfully!\")\n",
        "        print(\"ðŸ”§ Applied modifications:\")\n",
        "        print(\"   âœ“ No trajectory lines\")\n",
        "        print(\"   âœ“ Only Goalkeepers & Players tracked\")\n",
        "        print(\"   âœ“ Yellowish/green objects filtered out\")\n",
        "    else:\n",
        "        print(\"\\nâŒ Tracking failed!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
